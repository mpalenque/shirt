<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

    <script src="https://aframe.io/releases/1.5.0/aframe.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/mind-ar@1.2.5/dist/mindar-image-aframe.prod.js"></script>
    
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/control_utils"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/selfie_segmentation"></script>
    <title>Background Replacement with MindAR</title>
    <style>
       .container {
            width: 100%;
            height: 100%;
            position: fixed;
            top: 0;
            left: 0;
            z-index: 1000;
            opacity: 1;
        }
        .output_canvas {
            width: 100%;
            height: 100%;
            object-fit: cover;
            opacity: 1;
            position: absolute;
            top: 0;
            left: 0;
            z-index: 1001;
            -webkit-transform: translateZ(0);
        }
        .input_video {
            width: 100%;
            height: 100%;
            object-fit: cover;
            opacity: 0;
        }
        /* Hide only the video element inside MindAR a-scene */
        .mindar-video video {
            display: none;
        }
        /* Ensure MindAR 3D objects are above Mediapipe canvas */
        a-scene {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            z-index: 1002;
            pointer-events: none;
            background: transparent; /* Make background transparent */
        }
    </style>
</head>
<body>
    <div class="container">
        <video class="input_video" playsinline></video>
        <canvas class="output_canvas"></canvas>
    </div>

    <a-scene mindar-image="imageTargetSrc: https://mpalenque.github.io/shirt/assets/targets.mind; 
        filterMinCF: 0.9; 
        filterBeta: 0.0001; 
        warmupTolerance: 30; 
        missTolerance: 20; 
        trackingIntervalMilliseconds: 30;"
        color-space="sRGB" 
        renderer="colorManagement: true, physicallyCorrectLights, alpha: true" 
        vr-mode-ui="enabled: false" 
        device-orientation-permission-ui="enabled: false"
        class="mindar-video">
        
        <a-assets>
          <img id="card" src="/assets/yokkao.png" />
          <a-asset-item id="astro" src="https://mpalenque.github.io/shirt/assets/astro.glb"></a-asset-item>
        </a-assets>

        <a-camera position="0 0 0" look-controls="enabled: false"></a-camera>

        <a-entity mindar-image-target="targetIndex: 0">
            <a-gltf-model src="#astro" position="0.2 0 0.1" scale="0.4 0.4 0.4"
            animation="property: rotation; to: 0 360 0; loop: true; dur: 10000; easing: linear"
            animation__float="property: position; to: 0.2 0.2 0.1; dir: alternate; dur: 3000; loop: true; easing: easeInOutSine">
            </a-gltf-model>
        </a-entity>

        <a-light type="ambient" color="#ffffff"></a-light>
        <a-light type="directional" color="#ffffff" intensity="0.5" position="1 1 0"></a-light>
    </a-scene>

    <div id="status">Detection: not</div>

    <script>
        const videoElement = document.querySelector('.input_video');
        const canvasElement = document.querySelector('.output_canvas');
        const canvasCtx = canvasElement.getContext('2d');

        // Create and load background image
        const bgImage = new Image();
        bgImage.src = 'https://w0.peakpx.com/wallpaper/271/242/HD-wallpaper-autumn-tree-nature-forwest-sunset-thumbnail.jpg';
        
        // Set canvas size based on device
        function setCanvasSize() {
            const width = Math.min(window.innerWidth, 640);
            const height = (width * 4) / 3;
            canvasElement.width = width;
            canvasElement.height = height;
        }
        setCanvasSize();
        window.addEventListener('resize', setCanvasSize);

        function onResults(results) {
            canvasCtx.save();
            canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
            
            // Draw the background image first
            canvasCtx.drawImage(bgImage, 0, 0, canvasElement.width, canvasElement.height);
            
            // Draw the segmentation mask
            if (results.segmentationMask) {
                // Create a temporary canvas for the person
                const tempCanvas = document.createElement('canvas');
                tempCanvas.width = canvasElement.width;
                tempCanvas.height = canvasElement.height;
                const tempCtx = tempCanvas.getContext('2d');
                
                // Draw the original video frame
                tempCtx.drawImage(results.image, 0, 0, canvasElement.width, canvasElement.height);
                
                // Apply the segmentation mask
                tempCtx.globalCompositeOperation = 'destination-in';
                tempCtx.drawImage(results.segmentationMask, 0, 0, canvasElement.width, canvasElement.height);
                
                // Draw the masked person over the background
                canvasCtx.drawImage(tempCanvas, 0, 0);
            }
            
            canvasCtx.restore();
        }

        const selfieSegmentation = new SelfieSegmentation({
            locateFile: (file) => {
                return `https://cdn.jsdelivr.net/npm/@mediapipe/selfie_segmentation/${file}`;
            }
        });
        
        selfieSegmentation.setOptions({
            modelSelection: 1,
        });

        selfieSegmentation.onResults(onResults);

        // iOS optimized video constraints
        const constraints = {
            video: {
                width: { ideal: 1280 },
                height: { ideal: 720 },
                facingMode: 'user',
            }
        };

        // Start webcam with error handling
        async function startCamera() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia(constraints);
                videoElement.srcObject = stream;
                await videoElement.play();

                const processFrame = async () => {
                    try {
                        await selfieSegmentation.send({ image: videoElement });
                    } catch (error) {
                        console.error('Frame processing error:', error);
                    }
                    requestAnimationFrame(processFrame);
                };
                
                requestAnimationFrame(processFrame);
            } catch (error) {
                console.error('Camera access error:', error);
                alert('Could not access camera. Please ensure camera permissions are granted.');
            }
        }

        // Add playsinline attribute dynamically for iOS
        videoElement.setAttribute('playsinline', true);
        videoElement.setAttribute('webkit-playsinline', true);

        // Start camera when page is fully loaded
        document.addEventListener('DOMContentLoaded', startCamera);
    </script>
</body>
</html>